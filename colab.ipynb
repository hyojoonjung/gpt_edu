{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'law.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, mode='r') as file:\n",
    "    #print(file.readlines())\n",
    "    for i in range(20):\n",
    "        print(file.readline() , end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '안녕하세요 정효준  입니다 딥러닝은 어렵지 않습니다.'\n",
    "k = okt.pos(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenized = []\n",
    "with open(file_path , mode='r') as file:\n",
    "    while True:\n",
    "        line  = file.readline()\n",
    "        if not line : break\n",
    "        words = okt.pos(line, stem=True)\n",
    "        tokenized.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenized[:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3538e3d56709e678fe958d8106e85ad5fb55bdbefb75f2902995f21e682655b"
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 ('tweet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
